{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# IMDB Review\nGiven a IMDB movie review, classify it as positive or negative. Basically, it is a sentiment analysis.  \n\nFor doing so, I have used Bidirectional LSTM with Attention for better understanding the context of the review.  \n\nThis notebook is divided into the following sections:\n* Importing the libraries\n* Importing the dataset\n* Text Preprocessing\n* Attention\n* Building the model\n* Training\n* Testing\n***\n### Importing the libraries\nThe cell below is for importing the required libraries and for silencing the warnings","metadata":{}},{"cell_type":"code","source":"# !pip install tensorflow==1.14","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:45:18.747779Z","iopub.execute_input":"2022-12-01T16:45:18.748453Z","iopub.status.idle":"2022-12-01T16:45:18.805359Z","shell.execute_reply.started":"2022-12-01T16:45:18.748364Z","shell.execute_reply":"2022-12-01T16:45:18.804429Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# import numpy as np \n# with open('/kaggle/input/data-sentiment-foody-vn/data_train/data_train/train/neg/1.txt', encoding=\"utf8\") as f:\n#     lines = f.readlines()\n#     lines = \"\".join(lines)\n# print(lines)\n# print(type(lines))\n# print(np.shape(lines))","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:45:18.807422Z","iopub.execute_input":"2022-12-01T16:45:18.807796Z","iopub.status.idle":"2022-12-01T16:45:18.813772Z","shell.execute_reply.started":"2022-12-01T16:45:18.807757Z","shell.execute_reply":"2022-12-01T16:45:18.812582Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:45:18.815497Z","iopub.execute_input":"2022-12-01T16:45:18.816187Z","iopub.status.idle":"2022-12-01T16:45:18.825836Z","shell.execute_reply.started":"2022-12-01T16:45:18.816150Z","shell.execute_reply":"2022-12-01T16:45:18.825002Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip install pyvi","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:45:18.828906Z","iopub.execute_input":"2022-12-01T16:45:18.829528Z","iopub.status.idle":"2022-12-01T16:45:34.145002Z","shell.execute_reply.started":"2022-12-01T16:45:18.829483Z","shell.execute_reply":"2022-12-01T16:45:34.143683Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting pyvi\n  Downloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting sklearn-crfsuite\n  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from pyvi) (1.0.2)\nRequirement already satisfied: numpy>=1.14.6 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->pyvi) (1.21.6)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->pyvi) (1.0.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->pyvi) (3.1.0)\nRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->pyvi) (1.7.3)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from sklearn-crfsuite->pyvi) (0.9.0)\nRequirement already satisfied: tqdm>=2.0 in /opt/conda/lib/python3.7/site-packages (from sklearn-crfsuite->pyvi) (4.64.0)\nCollecting python-crfsuite>=0.8.3\n  Downloading python_crfsuite-0.9.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (965 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sklearn-crfsuite->pyvi) (1.15.0)\nInstalling collected packages: python-crfsuite, sklearn-crfsuite, pyvi\nSuccessfully installed python-crfsuite-0.9.8 pyvi-0.1.1 sklearn-crfsuite-0.3.6\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Ignoring the warnings\nimport warnings\nwarnings.filterwarnings('ignore')\nimport seaborn as sns\n#Importing the required libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport re, string, unicodedata\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import GlobalMaxPooling1D\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras import backend\nfrom sklearn.metrics import f1_score, confusion_matrix\nimport tensorflow as tf\n\nfrom pyvi import ViTokenizer\nfrom pyvi import ViUtils","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:45:34.147365Z","iopub.execute_input":"2022-12-01T16:45:34.147777Z","iopub.status.idle":"2022-12-01T16:45:45.805458Z","shell.execute_reply.started":"2022-12-01T16:45:34.147735Z","shell.execute_reply":"2022-12-01T16:45:45.804491Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### Importing the dataset\n***","metadata":{}},{"cell_type":"markdown","source":"# df1","metadata":{}},{"cell_type":"code","source":"df1 = pd.read_csv('/kaggle/input/int3405-sentiment-analysis-problem/full_train.csv')\ndf1 = df1.dropna()\n\ndf1 = df1.drop(['Unnamed: 0','RevId','UserId','image_urls'], axis=1)\nX_train1 = list(df1['Comment'].values)\ny_train1 = list(df1['Rating'].values)\nprint(df1.shape)\ndf1.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:45:45.807144Z","iopub.execute_input":"2022-12-01T16:45:45.807745Z","iopub.status.idle":"2022-12-01T16:45:46.087959Z","shell.execute_reply.started":"2022-12-01T16:45:45.807710Z","shell.execute_reply":"2022-12-01T16:45:46.086850Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"(9070, 2)\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                             Comment  Rating\n0  X√¥i d·∫ªo, ƒë·ªì ƒÉn ƒë·∫≠m v·ªã. H·ªôp x√¥i ƒë∆∞·ª£c l√≥t l√° tr√¥...     1.0\n1  G·ªçi ship 1 xu·∫•t cari g√† b√°nh naan v√† 3 mi·∫øng g...     0.0\n2  Th·ªùi ti·∫øt l·∫°nh nh∆∞ n√†y, c·∫£ nh√† r·ªß nhau ƒë·∫øn leg...     1.0\n3  Em c√≥ ƒë·ªçc review th·∫•y mng b·∫£o tr√† s·ªØa n∆∞·ªõng ƒë·ªÅ...     0.0\n4  ƒê·ªì ƒÉn r·∫•t ngon, nh√† h√†ng c≈©ng r·∫•t ƒë·∫πp, t·∫•t c·∫£ ...     1.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Comment</th>\n      <th>Rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>X√¥i d·∫ªo, ƒë·ªì ƒÉn ƒë·∫≠m v·ªã. H·ªôp x√¥i ƒë∆∞·ª£c l√≥t l√° tr√¥...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>G·ªçi ship 1 xu·∫•t cari g√† b√°nh naan v√† 3 mi·∫øng g...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Th·ªùi ti·∫øt l·∫°nh nh∆∞ n√†y, c·∫£ nh√† r·ªß nhau ƒë·∫øn leg...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Em c√≥ ƒë·ªçc review th·∫•y mng b·∫£o tr√† s·ªØa n∆∞·ªõng ƒë·ªÅ...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ƒê·ªì ƒÉn r·∫•t ngon, nh√† h√†ng c≈©ng r·∫•t ƒë·∫πp, t·∫•t c·∫£ ...</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## df2","metadata":{}},{"cell_type":"code","source":"# df2 = pd.read_csv('/kaggle/input/50k-data/data_1.csv')\n# df2 = df2.dropna()\n# df2 = df2.drop(['Score','RevId'], axis=1)\n# X_train2 = list(df2['Comment'].values)\n# y_train2 = list(df2['Rating'].values)\n# print(df2.shape)\n# df2.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:45:46.089389Z","iopub.execute_input":"2022-12-01T16:45:46.092156Z","iopub.status.idle":"2022-12-01T16:45:46.096869Z","shell.execute_reply.started":"2022-12-01T16:45:46.092114Z","shell.execute_reply":"2022-12-01T16:45:46.095567Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# df3\n","metadata":{}},{"cell_type":"code","source":"# df3 = pd.read_csv('/kaggle/input/data-100k/extra_150k.csv')\n# df3 = df3.dropna()\n# # df2 = df2.drop(['Score','RevId'], axis=1)\n# X_train3 = list(df3['Comment'].values)\n# y_train3 = list(df3['Rating'].values)\n# print(df3.shape)\n# df2.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:45:46.100815Z","iopub.execute_input":"2022-12-01T16:45:46.101239Z","iopub.status.idle":"2022-12-01T16:45:46.111436Z","shell.execute_reply.started":"2022-12-01T16:45:46.101208Z","shell.execute_reply":"2022-12-01T16:45:46.110233Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"X_train = X_train1 #+ X_train2 + X_train3\nprint(len(X_train))\ny_train = y_train1 #+ y_train2 + y_train3","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:45:46.112802Z","iopub.execute_input":"2022-12-01T16:45:46.114163Z","iopub.status.idle":"2022-12-01T16:45:46.125529Z","shell.execute_reply.started":"2022-12-01T16:45:46.114109Z","shell.execute_reply":"2022-12-01T16:45:46.124214Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"9070\n","output_type":"stream"}]},{"cell_type":"code","source":"sum(y_train)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:45:46.127661Z","iopub.execute_input":"2022-12-01T16:45:46.128151Z","iopub.status.idle":"2022-12-01T16:45:46.139566Z","shell.execute_reply.started":"2022-12-01T16:45:46.128120Z","shell.execute_reply":"2022-12-01T16:45:46.138697Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"7146.0"},"metadata":{}}]},{"cell_type":"code","source":"sum(y_train)/len(y_train)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:45:46.141540Z","iopub.execute_input":"2022-12-01T16:45:46.142383Z","iopub.status.idle":"2022-12-01T16:45:46.159544Z","shell.execute_reply.started":"2022-12-01T16:45:46.142345Z","shell.execute_reply":"2022-12-01T16:45:46.158590Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"0.7878721058434399"},"metadata":{}}]},{"cell_type":"code","source":"sns.countplot(y_train)\n","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:45:46.161346Z","iopub.execute_input":"2022-12-01T16:45:46.161791Z","iopub.status.idle":"2022-12-01T16:45:46.417257Z","shell.execute_reply.started":"2022-12-01T16:45:46.161759Z","shell.execute_reply":"2022-12-01T16:45:46.416190Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:ylabel='count'>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"### Text Preprocessing\n***\nPreprocessing the text so as to have a better data for our model.  \nIt comprises of steps such as removing non-ASCII characters, removing HTML tags, converting to lower-case, lemmatizing.","metadata":{}},{"cell_type":"code","source":"def clean_text_2(text):\n    RE_EMOJI = re.compile('[\\U00010000-\\U0010ffff]', flags=re.UNICODE)\n    text = re.sub(r\"<.*?>\", \" \", text)\n    text = re.sub(r\"\\n\", \" \", text)\n    text = re.sub(r\"\\s{2,}\", \" \", text)\n    text = RE_EMOJI.sub(r'', text)\n    return text.strip().lower()","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:45:46.418620Z","iopub.execute_input":"2022-12-01T16:45:46.419226Z","iopub.status.idle":"2022-12-01T16:45:46.427052Z","shell.execute_reply.started":"2022-12-01T16:45:46.419188Z","shell.execute_reply":"2022-12-01T16:45:46.425663Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# stopwords_vn = []\n# src = '/kaggle/input/vietnamesestopword/vietnamese-stopwords.txt'\n# with open(src,'r', encoding = 'utf-8') as f:\n#     for line in f:\n#         stopwords_vn.append(line.strip())","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:45:46.428352Z","iopub.execute_input":"2022-12-01T16:45:46.430566Z","iopub.status.idle":"2022-12-01T16:45:46.437241Z","shell.execute_reply.started":"2022-12-01T16:45:46.430528Z","shell.execute_reply":"2022-12-01T16:45:46.436004Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def tokenizer_vn(text):\n    text = ViTokenizer.tokenize(text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:45:46.438856Z","iopub.execute_input":"2022-12-01T16:45:46.439325Z","iopub.status.idle":"2022-12-01T16:45:46.449526Z","shell.execute_reply.started":"2022-12-01T16:45:46.439285Z","shell.execute_reply":"2022-12-01T16:45:46.448532Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# stopwords_vn = [tokenizer_vn(word) for word in stopwords_vn]\n# def remove_stopwords(text):\n#     text = text.split()\n#     text = [word for word in text if word not in stopwords_vn]\n#     return ' '.join(text)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:45:46.451032Z","iopub.execute_input":"2022-12-01T16:45:46.451464Z","iopub.status.idle":"2022-12-01T16:45:46.463109Z","shell.execute_reply.started":"2022-12-01T16:45:46.451428Z","shell.execute_reply":"2022-12-01T16:45:46.461959Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def clean_text(X):\n    processed = []\n    for text in X:\n        text = clean_text_2(text)\n        text = ViTokenizer.tokenize(text)\n        processed.append(text)\n    return processed","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:45:46.464452Z","iopub.execute_input":"2022-12-01T16:45:46.464900Z","iopub.status.idle":"2022-12-01T16:45:46.475661Z","shell.execute_reply.started":"2022-12-01T16:45:46.464858Z","shell.execute_reply":"2022-12-01T16:45:46.474655Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Preprocessing the Training Set and Test set","metadata":{}},{"cell_type":"code","source":"text_test = X_train[13]\nprint(text_test)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:45:46.477291Z","iopub.execute_input":"2022-12-01T16:45:46.477736Z","iopub.status.idle":"2022-12-01T16:45:46.491030Z","shell.execute_reply.started":"2022-12-01T16:45:46.477702Z","shell.execute_reply":"2022-12-01T16:45:46.489987Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Qu√°n ƒë∆∞·ª£c to·∫° ngay v·ªã tr√≠ ƒë·ªëi di·ªán l√† trung t√¢m nh√† h√°t l·ªõn. ·ªû ngay ƒë·∫ßu ng√µ n√™n d·ªÖ t√¨m, kh√¥ng kh√≠ kh√° y√™n tƒ©nh kh√¥ng ·ªìn √†o. Qu√°n m·ªõi n√¢ng c·∫•p b√†n gh·∫ø, c√≥ ƒëi·ªÅu ho√† m√°t r∆∞·ª£i, t·∫°o c·∫£m gi√°c kh√¥ng gian sang tr·ªçng v√† l·ªãch thi·ªáp. C√≥ th·ªÉ ng·ªìi ngo√†i ng√µ. Menu r·∫•t nhi·ªÅu m√≥n ·ªëc, ƒë·∫≠m ch·∫•t s√†i g√≤n lu√¥n. Nh∆∞ng so v·ªõi b·ªçn sinh vi√™n m√¨nh th√¨ th·ª±c s·ª± gi√° h∆°i ch√°t. üòìüòìüòì ƒÉn c≈©ng ƒë∆∞·ª£c, l·∫° mi·ªáng. Ch·ªã nh√¢n vi√™n ph·ª•c v·ª• c≈©ng t·∫°m, m·∫∑t h∆°i l·∫°nh l√πng üòíüòíüòí n√≥i chung l√† ƒë·∫øn ƒë·ªÉ ƒÉn th·ª≠ v√¨ nghe t√™n r·∫•t l√¢u r·ªìi, ch·ª© ko d√°m quay l·∫°i v√¨ kh√° t·ªën k√©m :))\n","output_type":"stream"}]},{"cell_type":"code","source":"# test2 = tokenizer_vn(clean_text_2(text_test))\n# print(test2)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:46:11.895603Z","iopub.execute_input":"2022-12-01T16:46:11.895973Z","iopub.status.idle":"2022-12-01T16:46:11.900981Z","shell.execute_reply.started":"2022-12-01T16:46:11.895941Z","shell.execute_reply":"2022-12-01T16:46:11.899765Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# test2 = remove_stopwords(clean_text_2(text_test))\n# print(test2)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:45:46.510308Z","iopub.execute_input":"2022-12-01T16:45:46.510924Z","iopub.status.idle":"2022-12-01T16:45:46.521436Z","shell.execute_reply.started":"2022-12-01T16:45:46.510886Z","shell.execute_reply":"2022-12-01T16:45:46.520272Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# test2 = remove_stopwords(tokenizer_vn(clean_text_2(text_test)))\n# print(test2)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:45:46.522762Z","iopub.execute_input":"2022-12-01T16:45:46.523579Z","iopub.status.idle":"2022-12-01T16:45:46.535126Z","shell.execute_reply.started":"2022-12-01T16:45:46.523544Z","shell.execute_reply":"2022-12-01T16:45:46.534108Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# X_train_final,y_train = clean_text(X_train), y_train\n# X_test_final,y_test = clean_text(X_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:45:46.536740Z","iopub.execute_input":"2022-12-01T16:45:46.537954Z","iopub.status.idle":"2022-12-01T16:45:46.547578Z","shell.execute_reply.started":"2022-12-01T16:45:46.537919Z","shell.execute_reply":"2022-12-01T16:45:46.546436Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"#clean_text_load = pd.read_csv('/kaggle/input/data-clean100k/data_clean.csv')\n#clean_text_load = clean_text_load.dropna()","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:45:52.046998Z","iopub.execute_input":"2022-12-01T16:45:52.047389Z","iopub.status.idle":"2022-12-01T16:45:52.052316Z","shell.execute_reply.started":"2022-12-01T16:45:52.047356Z","shell.execute_reply":"2022-12-01T16:45:52.050976Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# clean_text_load.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:46:15.911497Z","iopub.execute_input":"2022-12-01T16:46:15.911902Z","iopub.status.idle":"2022-12-01T16:46:15.918099Z","shell.execute_reply.started":"2022-12-01T16:46:15.911868Z","shell.execute_reply":"2022-12-01T16:46:15.916880Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# clean_text_load.shape","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:45:46.926194Z","iopub.status.idle":"2022-12-01T16:45:46.926611Z","shell.execute_reply.started":"2022-12-01T16:45:46.926406Z","shell.execute_reply":"2022-12-01T16:45:46.926425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train_final = list(clean_text_load['Comment'].values)\n# y_train = list(clean_text_load['Rating'].values)\nX_train_final = X_train\n#y_train ","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:47:05.406899Z","iopub.execute_input":"2022-12-01T16:47:05.407622Z","iopub.status.idle":"2022-12-01T16:47:05.412185Z","shell.execute_reply.started":"2022-12-01T16:47:05.407586Z","shell.execute_reply":"2022-12-01T16:47:05.411128Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"len(X_train_final)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:47:14.919080Z","iopub.execute_input":"2022-12-01T16:47:14.919433Z","iopub.status.idle":"2022-12-01T16:47:14.925688Z","shell.execute_reply.started":"2022-12-01T16:47:14.919405Z","shell.execute_reply":"2022-12-01T16:47:14.924470Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"9070"},"metadata":{}}]},{"cell_type":"markdown","source":"# take 100","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# my_data_new = pd.DataFrame({'Comment': X_train_final, 'Rating': y_train})\n# my_data_new.to_csv('data_clean.csv', index=False)\n# my_data_new.shape","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:47:15.485230Z","iopub.execute_input":"2022-12-01T16:47:15.486040Z","iopub.status.idle":"2022-12-01T16:47:15.491146Z","shell.execute_reply.started":"2022-12-01T16:47:15.486003Z","shell.execute_reply":"2022-12-01T16:47:15.489798Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train_final[:2])\nprint(y_train[:2])","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:47:16.485149Z","iopub.execute_input":"2022-12-01T16:47:16.485953Z","iopub.status.idle":"2022-12-01T16:47:16.491497Z","shell.execute_reply.started":"2022-12-01T16:47:16.485916Z","shell.execute_reply":"2022-12-01T16:47:16.490255Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"['X√¥i d·∫ªo, ƒë·ªì ƒÉn ƒë·∫≠m v·ªã. H·ªôp x√¥i ƒë∆∞·ª£c l√≥t l√° tr√¥ng r·∫•t th√≠ch', 'G·ªçi ship 1 xu·∫•t cari g√† b√°nh naan v√† 3 mi·∫øng g√† n∆∞·ªõng(ƒë∆∞·ª£c t·∫∑ng 1 coca). ƒê·ªì ƒÉn kh√° ngon, t·ªïng 210k ƒë∆∞·ª£c gi·∫£m 50k c√≤n 160k. Tuy nhi√™n g·ªçi 3 mi·∫øng g√† th√¨ thi·∫øu 1 mi·∫øng, m√† k·ªÉ c·∫£ ƒë√≥ ƒë·ªß ba mi·∫øng th√¨ kh·∫©u ph·∫ßn v·∫´n l√† qu√° √≠t so v·ªõi gi√° 120k 1 su·∫•t.']\n[1.0, 0.0]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Attention Layer\n***\n\nThe basic concept of attention is that not all words contribute equally to the meaning of a sentence. Hence, their contribution must be weighted.  \nHow attention works is, it basically extracts words that are important to the meaning of the sentence and aggregate the representation of those informative words to form a sentence vector.","metadata":{}},{"cell_type":"code","source":"# Attention Layer\nfrom tensorflow.keras import initializers,regularizers,constraints\nfrom tensorflow.keras import backend as K\nclass AttentionWithContext(tf.keras.layers.Layer):\n    \"\"\"\n    Attention operation, with a context/query vector, for temporal data.\n    Supports Masking.\n    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n    \"Hierarchical Attention Networks for Document Classification\"\n    by using a context vector to assist the attention\n    # Input shape\n        3D tensor with shape: `(samples, steps, features)`.\n    # Output shape\n        2D tensor with shape: `(samples, features)`.\n    How to use:\n    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n    The dimensions are inferred based on the output shape of the RNN.\n    Note: The layer has been tested with Keras 2.0.6\n    Example:\n        model.add(LSTM(64, return_sequences=True))\n        model.add(AttentionWithContext())\n        # next add a Dense layer (for classification/regression) or whatever...\n    \"\"\"\n\n    def __init__(self, W_regularizer=None, u_regularizer=None, b_regularizer=None,\n                 W_constraint=None, u_constraint=None, b_constraint=None,\n                 bias=True, **kwargs):\n\n        self.supports_masking = True\n        self.init = initializers.get('glorot_uniform')\n\n        self.W_regularizer = regularizers.get(W_regularizer)\n        self.u_regularizer = regularizers.get(u_regularizer)\n        self.b_regularizer = regularizers.get(b_regularizer)\n\n        self.W_constraint = constraints.get(W_constraint)\n        self.u_constraint = constraints.get(u_constraint)\n        self.b_constraint = constraints.get(b_constraint)\n\n        self.bias = bias\n        super(AttentionWithContext, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        assert len(input_shape) == 3\n\n        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1],),\n                                 initializer=self.init,\n                                 name='{}_W'.format(self.name),\n                                 regularizer=self.W_regularizer,\n                                 constraint=self.W_constraint)\n        if self.bias:\n            self.b = self.add_weight(shape=(input_shape[-1],),\n                                     initializer='zero',\n                                     name='{}_b'.format(self.name),\n                                     regularizer=self.b_regularizer,\n                                     constraint=self.b_constraint)\n\n        self.u = self.add_weight(shape=(input_shape[-1],),\n                                 initializer=self.init,\n                                 name='{}_u'.format(self.name),\n                                 regularizer=self.u_regularizer,\n                                 constraint=self.u_constraint)\n\n        super(AttentionWithContext, self).build(input_shape)\n\n    def compute_mask(self, input, input_mask=None):\n        # do not pass the mask to the next layers\n        return None\n    def get_config(self):\n        config = super().get_config().copy()\n        config.update({\n            'W_regularizer': self.W_regularizer,\n            'u_regularizer': self.u_regularizer,\n            'b_regularizer': self.b_regularizer,\n            'W_constraint': self.W_constraint,\n            'u_constraint': self.u_constraint,\n            'b_constraint': self.b_constraint,\n            'bias': self.bias,\n            })\n        return config\n    def call(self, x, mask=None):\n        uit = dot_product(x, self.W)\n\n        if self.bias:\n            uit += self.b\n\n        uit = K.tanh(uit)\n        ait = dot_product(uit, self.u)\n\n        a = K.exp(ait)\n\n        # apply mask after the exp. will be re-normalized next\n        if mask is not None:\n            # Cast the mask to floatX to avoid float64 upcasting in theano\n            a *= K.cast(mask, K.floatx())\n\n        # in some cases especially in the early stages of training the sum may be almost zero\n        # and this results in NaN's. A workaround is to add a very small positive number Œµ to the sum.\n        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n\n        a = K.expand_dims(a)\n        weighted_input = x * a\n        return K.sum(weighted_input, axis=1)\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0], input_shape[-1]\n\ndef dot_product(x, kernel):\n    \"\"\"\n    Wrapper for dot product operation, in order to be compatible with both\n    Theano and Tensorflow\n    Args:\n        x (): input\n        kernel (): weights\n    Returns:\n    \"\"\"\n    if K.backend() == 'tensorflow':\n        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n    else:\n        return K.dot(x, kernel)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:47:17.341992Z","iopub.execute_input":"2022-12-01T16:47:17.342364Z","iopub.status.idle":"2022-12-01T16:47:17.361432Z","shell.execute_reply.started":"2022-12-01T16:47:17.342332Z","shell.execute_reply":"2022-12-01T16:47:17.360301Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"Some Useful Variables  \n","metadata":{}},{"cell_type":"code","source":"#Tokenization and Padding\nvocab_size = 60000\nmaxlen = 250\nencode_dim = 20\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(X_train_final)\ntokenized_word_list = tokenizer.texts_to_sequences(X_train_final)\nX_train_padded = pad_sequences(tokenized_word_list, maxlen = maxlen, padding='post')","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:47:18.469323Z","iopub.execute_input":"2022-12-01T16:47:18.469672Z","iopub.status.idle":"2022-12-01T16:47:20.097799Z","shell.execute_reply.started":"2022-12-01T16:47:18.469642Z","shell.execute_reply":"2022-12-01T16:47:20.096798Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(np.shape(X_train_padded))\n# print(np.shape(X_train_final))","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:47:20.099828Z","iopub.execute_input":"2022-12-01T16:47:20.100388Z","iopub.status.idle":"2022-12-01T16:47:20.106861Z","shell.execute_reply.started":"2022-12-01T16:47:20.100343Z","shell.execute_reply":"2022-12-01T16:47:20.105668Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"**EarlyStopping**  \nIt can be used to prevent overfitting.It basically waits a few epochs (5), monitoring the loss for the validation dataset.If the loss doesn't decrease for 2 epochs, it stops the training process.\n\n**ModelCheckpoint**  \nIt is used for saving the best model during training. After each epoch, it takes a look at the Validation accuracy, if it improves globally, this is the best model we have seen till now during the training process and hence, saves it.","metadata":{}},{"cell_type":"code","source":"#EarlyStopping and ModelCheckpoint\n\nes = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 5)\nmc = ModelCheckpoint('model_best.h5', monitor = 'val_loss', mode = 'min', verbose = 1, save_best_only = True)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:47:20.108240Z","iopub.execute_input":"2022-12-01T16:47:20.109178Z","iopub.status.idle":"2022-12-01T16:47:20.118050Z","shell.execute_reply.started":"2022-12-01T16:47:20.109140Z","shell.execute_reply":"2022-12-01T16:47:20.117211Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"### Building the Model\n***\nThe model used comprises of BiDirectional LSTM with Attention layer on top of it, followed by a dense layer and finally a dense layer with sigmoid activation function to get the sentiment or the class.  \nOptimiser used is ADAM","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import layers","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:47:21.092103Z","iopub.execute_input":"2022-12-01T16:47:21.092457Z","iopub.status.idle":"2022-12-01T16:47:21.097165Z","shell.execute_reply.started":"2022-12-01T16:47:21.092428Z","shell.execute_reply":"2022-12-01T16:47:21.096062Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Building the model\ndef create_model():\n    model = Sequential()\n    embed = Embedding(input_dim = vocab_size, output_dim = 20, input_length = X_train_padded.shape[1]\n    #                   , dropout = 0.4\n                     ) \n    model.add(embed)\n    model.add(Dropout(0.4))\n    model.add(Bidirectional(LSTM(200, return_sequences = True)))\n    # model.add(Dropout(0.3))\n    # model.add(Bidirectional(GRU(200, return_sequences = True)))\n    model.add(Dropout(0.3))\n    model.add(AttentionWithContext())\n    model.add(Dropout(0.3))\n    model.add(Dense(512))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dense(256))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dense(1, activation = 'sigmoid'))\n    model.summary()\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:47:21.415371Z","iopub.execute_input":"2022-12-01T16:47:21.415741Z","iopub.status.idle":"2022-12-01T16:47:21.423613Z","shell.execute_reply.started":"2022-12-01T16:47:21.415708Z","shell.execute_reply":"2022-12-01T16:47:21.422638Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"### Training\n***\nSplitting the Training set into Training set and Validation set","metadata":{}},{"cell_type":"markdown","source":"## split","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train_padded = np.asarray(X_train_padded)\ny_train = np.asarray(y_train)\n# X_train_final2, X_val, y_train_final2, y_val = train_test_split(X_train_padded, y_train, test_size = 0.1)\nX_train_final2 = X_train_padded\ny_train_final2 = y_train","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:47:21.844975Z","iopub.execute_input":"2022-12-01T16:47:21.845360Z","iopub.status.idle":"2022-12-01T16:47:21.875903Z","shell.execute_reply.started":"2022-12-01T16:47:21.845329Z","shell.execute_reply":"2022-12-01T16:47:21.874926Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"print(type(X_train_final2))","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:47:22.006235Z","iopub.execute_input":"2022-12-01T16:47:22.006556Z","iopub.status.idle":"2022-12-01T16:47:22.011952Z","shell.execute_reply.started":"2022-12-01T16:47:22.006531Z","shell.execute_reply":"2022-12-01T16:47:22.010747Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"<class 'numpy.ndarray'>\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Training the model","metadata":{}},{"cell_type":"code","source":"y_train_final2.shape","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:47:22.350261Z","iopub.execute_input":"2022-12-01T16:47:22.350881Z","iopub.status.idle":"2022-12-01T16:47:22.356797Z","shell.execute_reply.started":"2022-12-01T16:47:22.350844Z","shell.execute_reply":"2022-12-01T16:47:22.355715Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"(9070,)"},"metadata":{}}]},{"cell_type":"code","source":"weight = sum(y_train_final2) / y_train_final2.shape[0]\nprint(weight)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:47:22.539599Z","iopub.execute_input":"2022-12-01T16:47:22.540617Z","iopub.status.idle":"2022-12-01T16:47:22.547843Z","shell.execute_reply.started":"2022-12-01T16:47:22.540574Z","shell.execute_reply":"2022-12-01T16:47:22.546793Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"0.7878721058434399\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## weight","metadata":{}},{"cell_type":"code","source":"#class weight\nweight_for_0 = (1 / (1-(weight))) * 0.5\nweight_for_1 = (1 / (weight))* 0.5\nclass_weight = {0: weight_for_0, 1: weight_for_1}","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:47:22.971913Z","iopub.execute_input":"2022-12-01T16:47:22.972263Z","iopub.status.idle":"2022-12-01T16:47:22.979719Z","shell.execute_reply.started":"2022-12-01T16:47:22.972235Z","shell.execute_reply":"2022-12-01T16:47:22.978817Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"print(tf. __version__) ","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:47:23.170638Z","iopub.execute_input":"2022-12-01T16:47:23.171002Z","iopub.status.idle":"2022-12-01T16:47:23.176967Z","shell.execute_reply.started":"2022-12-01T16:47:23.170964Z","shell.execute_reply":"2022-12-01T16:47:23.175427Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"2.6.4\n","output_type":"stream"}]},{"cell_type":"code","source":"es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 5)\nmc = ModelCheckpoint('model_best.h5', monitor = 'f1_score', mode = 'min', verbose = 1, save_best_only = True)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:47:23.329928Z","iopub.execute_input":"2022-12-01T16:47:23.330331Z","iopub.status.idle":"2022-12-01T16:47:23.335742Z","shell.execute_reply.started":"2022-12-01T16:47:23.330289Z","shell.execute_reply":"2022-12-01T16:47:23.334606Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"batch_size= 300\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='f1_score', factor=0.2,\n                              patience=3, min_lr=1e-5,verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:47:23.516824Z","iopub.execute_input":"2022-12-01T16:47:23.517186Z","iopub.status.idle":"2022-12-01T16:47:23.522155Z","shell.execute_reply.started":"2022-12-01T16:47:23.517159Z","shell.execute_reply":"2022-12-01T16:47:23.521042Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"import tensorflow_addons as tfa","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:47:23.696751Z","iopub.execute_input":"2022-12-01T16:47:23.697219Z","iopub.status.idle":"2022-12-01T16:47:23.939649Z","shell.execute_reply.started":"2022-12-01T16:47:23.697178Z","shell.execute_reply":"2022-12-01T16:47:23.938704Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"# CPU","metadata":{}},{"cell_type":"code","source":"# optim =  tf.keras.optimizers.Adam(learning_rate=5e-4)\n\n# model.compile(optimizer='adam',\n#                      loss='binary_crossentropy',\n#                      metrics=['accuracy',\n# #                               tf.keras.metrics.Precision(),\n#                               tf.keras.metrics.Recall(),\n#                               tfa.metrics.F1Score(num_classes=1,\n#                                                  average='micro')\n#                              ]\n#              )","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:47:24.090436Z","iopub.execute_input":"2022-12-01T16:47:24.090769Z","iopub.status.idle":"2022-12-01T16:47:24.095780Z","shell.execute_reply.started":"2022-12-01T16:47:24.090740Z","shell.execute_reply":"2022-12-01T16:47:24.094562Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"# TPU","metadata":{}},{"cell_type":"code","source":"# tpu_strategy = tf.distribute.MirroredStrategy()\ntpu_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n\n","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:47:24.802114Z","iopub.execute_input":"2022-12-01T16:47:24.803424Z","iopub.status.idle":"2022-12-01T16:47:30.519715Z","shell.execute_reply.started":"2022-12-01T16:47:24.803378Z","shell.execute_reply":"2022-12-01T16:47:30.518767Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stderr","text":"2022-12-01 16:47:24.921446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-01 16:47:24.922436: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-01 16:47:25.254730: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-01 16:47:25.255638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-01 16:47:25.256510: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-01 16:47:25.257335: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-01 16:47:25.261999: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-12-01 16:47:25.536714: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-01 16:47:25.537573: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-01 16:47:25.538293: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-01 16:47:25.539036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-01 16:47:25.539727: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-01 16:47:25.540433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-01 16:47:29.794862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-01 16:47:29.795800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-01 16:47:29.796664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-01 16:47:29.797460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-01 16:47:29.798156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-01 16:47:29.798818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13789 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n2022-12-01 16:47:29.803509: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-01 16:47:29.804220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13789 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"}]},{"cell_type":"code","source":"# detect and init the TPU\n# tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n# print(tpu)\n# instantiate a distribution strategy\n# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\ntpu_strategy = tf.distribute.MirroredStrategy()\n\n# # instantiating the model in the strategy scope creates the model on the TPU\nwith tpu_strategy.scope():\n    model = create_model() # define your model normally\n    optim =  tf.keras.optimizers.Adam(learning_rate=5e-4)\n\n    model.compile(optimizer='adam',\n                     loss='binary_crossentropy',\n                     metrics=['accuracy',\n#                               tf.keras.metrics.Precision(),\n                              tf.keras.metrics.Recall(),\n                              tfa.metrics.F1Score(num_classes=1,\n                                                 average='micro')\n                             ]\n             )\n\n","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:47:30.522318Z","iopub.execute_input":"2022-12-01T16:47:30.523121Z","iopub.status.idle":"2022-12-01T16:47:31.458652Z","shell.execute_reply.started":"2022-12-01T16:47:30.523082Z","shell.execute_reply":"2022-12-01T16:47:31.457693Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 250, 20)           1200000   \n_________________________________________________________________\ndropout (Dropout)            (None, 250, 20)           0         \n_________________________________________________________________\nbidirectional (Bidirectional (None, 250, 400)          353600    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 250, 400)          0         \n_________________________________________________________________\nattention_with_context (Atte (None, 400)               160800    \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 400)               0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               205312    \n_________________________________________________________________\nleaky_re_lu (LeakyReLU)      (None, 512)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 256)               131328    \n_________________________________________________________________\nleaky_re_lu_1 (LeakyReLU)    (None, 256)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 257       \n=================================================================\nTotal params: 2,051,297\nTrainable params: 2,051,297\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"len(X_train_final2)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:47:31.459922Z","iopub.execute_input":"2022-12-01T16:47:31.460446Z","iopub.status.idle":"2022-12-01T16:47:31.473766Z","shell.execute_reply.started":"2022-12-01T16:47:31.460410Z","shell.execute_reply":"2022-12-01T16:47:31.472818Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"9070"},"metadata":{}}]},{"cell_type":"code","source":"train_x, train_y = np.array(X_train_final2), np.array(y_train_final2)\n# val_x, val_y = np.array(...), np.array(...)\n\n# Wrap data in Dataset objects.\ntrain_data = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n# val_data = tf.data.Dataset.from_tensor_slices((val_x, val_y))","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:47:31.480678Z","iopub.execute_input":"2022-12-01T16:47:31.483259Z","iopub.status.idle":"2022-12-01T16:47:31.512469Z","shell.execute_reply.started":"2022-12-01T16:47:31.483221Z","shell.execute_reply":"2022-12-01T16:47:31.511377Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"train_x","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:47:31.514156Z","iopub.execute_input":"2022-12-01T16:47:31.514888Z","iopub.status.idle":"2022-12-01T16:47:31.525500Z","shell.execute_reply.started":"2022-12-01T16:47:31.514830Z","shell.execute_reply":"2022-12-01T16:47:31.524487Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"array([[ 328,  441,   17, ...,    0,    0,    0],\n       [  31,  234,   16, ...,    0,    0,    0],\n       [ 527,  617,  370, ...,    0,    0,    0],\n       ...,\n       [ 170,  114,  117, ...,    0,    0,    0],\n       [  99,    1,   74, ...,    0,    0,    0],\n       [ 179,  311, 1109, ...,    0,    0,    0]], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"train_y","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:47:31.526882Z","iopub.execute_input":"2022-12-01T16:47:31.527894Z","iopub.status.idle":"2022-12-01T16:47:31.542133Z","shell.execute_reply.started":"2022-12-01T16:47:31.527852Z","shell.execute_reply":"2022-12-01T16:47:31.541126Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"array([1., 0., 1., ..., 1., 1., 1.])"},"metadata":{}}]},{"cell_type":"code","source":"batch_size = 512 * tpu_strategy.num_replicas_in_sync\n\ntrain_data = train_data.batch(batch_size)\n# val_data = val_data.batch(batch_size)\n# Disable AutoShard.\noptions = tf.data.Options()\noptions.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\ntrain_data = train_data.with_options(options)\n# val_data = val_data.with_options(options)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:47:31.544092Z","iopub.execute_input":"2022-12-01T16:47:31.544979Z","iopub.status.idle":"2022-12-01T16:47:31.562396Z","shell.execute_reply.started":"2022-12-01T16:47:31.544939Z","shell.execute_reply":"2022-12-01T16:47:31.561191Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"#Fitting the model\nmodel.fit(train_data ,\n          epochs = 15, batch_size = batch_size, verbose = 1,\n#           validation_data = (X_val, y_val),\n          callbacks = [reduce_lr, es,mc],class_weight=class_weight)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:47:31.564201Z","iopub.execute_input":"2022-12-01T16:47:31.565104Z","iopub.status.idle":"2022-12-01T16:48:22.219261Z","shell.execute_reply.started":"2022-12-01T16:47:31.565063Z","shell.execute_reply":"2022-12-01T16:48:22.218293Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stderr","text":"2022-12-01 16:47:31.700326: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/15\n","output_type":"stream"},{"name":"stderr","text":"2022-12-01 16:47:43.337535: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n2022-12-01 16:47:44.370346: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"9/9 [==============================] - 18s 237ms/step - loss: 0.6920 - accuracy: 0.3531 - recall: 0.2333 - f1_score: 0.8814\n\nEpoch 00001: f1_score improved from inf to 0.88135, saving model to model_best.h5\nEpoch 2/15\n9/9 [==============================] - 2s 236ms/step - loss: 0.6829 - accuracy: 0.5593 - recall: 0.5605 - f1_score: 0.8814\n\nEpoch 00002: f1_score did not improve from 0.88135\nEpoch 3/15\n9/9 [==============================] - 2s 234ms/step - loss: 0.6249 - accuracy: 0.6387 - recall: 0.6117 - f1_score: 0.8814\n\nEpoch 00003: f1_score did not improve from 0.88135\nEpoch 4/15\n9/9 [==============================] - 2s 234ms/step - loss: 0.4685 - accuracy: 0.8303 - recall: 0.8476 - f1_score: 0.8814\n\nEpoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n\nEpoch 00004: f1_score did not improve from 0.88135\nEpoch 5/15\n9/9 [==============================] - 2s 236ms/step - loss: 0.3840 - accuracy: 0.8774 - recall: 0.9053 - f1_score: 0.8814\n\nEpoch 00005: f1_score did not improve from 0.88135\nEpoch 6/15\n9/9 [==============================] - 2s 233ms/step - loss: 0.3624 - accuracy: 0.8664 - recall: 0.8762 - f1_score: 0.8814\n\nEpoch 00006: f1_score did not improve from 0.88135\nEpoch 7/15\n9/9 [==============================] - 2s 237ms/step - loss: 0.3476 - accuracy: 0.8825 - recall: 0.8984 - f1_score: 0.8814\n\nEpoch 00007: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n\nEpoch 00007: f1_score did not improve from 0.88135\nEpoch 8/15\n9/9 [==============================] - 2s 236ms/step - loss: 0.3427 - accuracy: 0.8816 - recall: 0.8949 - f1_score: 0.8814\n\nEpoch 00008: f1_score did not improve from 0.88135\nEpoch 9/15\n9/9 [==============================] - 2s 238ms/step - loss: 0.3334 - accuracy: 0.8856 - recall: 0.8981 - f1_score: 0.8814\n\nEpoch 00009: f1_score did not improve from 0.88135\nEpoch 10/15\n9/9 [==============================] - 2s 242ms/step - loss: 0.3304 - accuracy: 0.8850 - recall: 0.8980 - f1_score: 0.8814\n\nEpoch 00010: ReduceLROnPlateau reducing learning rate to 1e-05.\n\nEpoch 00010: f1_score did not improve from 0.88135\nEpoch 11/15\n9/9 [==============================] - 2s 235ms/step - loss: 0.3328 - accuracy: 0.8879 - recall: 0.9023 - f1_score: 0.8814\n\nEpoch 00011: f1_score did not improve from 0.88135\nEpoch 12/15\n9/9 [==============================] - 2s 249ms/step - loss: 0.3313 - accuracy: 0.8843 - recall: 0.8987 - f1_score: 0.8814\n\nEpoch 00012: f1_score did not improve from 0.88135\nEpoch 13/15\n9/9 [==============================] - 2s 238ms/step - loss: 0.3320 - accuracy: 0.8861 - recall: 0.8984 - f1_score: 0.8814\n\nEpoch 00013: f1_score did not improve from 0.88135\nEpoch 14/15\n9/9 [==============================] - 2s 251ms/step - loss: 0.3275 - accuracy: 0.8877 - recall: 0.8998 - f1_score: 0.8814\n\nEpoch 00014: f1_score did not improve from 0.88135\nEpoch 15/15\n9/9 [==============================] - 2s 240ms/step - loss: 0.3248 - accuracy: 0.8906 - recall: 0.9032 - f1_score: 0.8814\n\nEpoch 00015: f1_score did not improve from 0.88135\n","output_type":"stream"},{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f795c680e10>"},"metadata":{}}]},{"cell_type":"code","source":"# #Fitting the model\n# batch_size = 512 #* tpu_strategy.num_replicas_in_sync\n# model.fit(X_train_final2, y_train_final2, \n#           epochs = 15, batch_size = batch_size, verbose = 1,\n# #           validation_data = (X_val, y_val),\n#           callbacks = [reduce_lr, es,mc],class_weight=class_weight)\n","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:48:22.220908Z","iopub.execute_input":"2022-12-01T16:48:22.221343Z","iopub.status.idle":"2022-12-01T16:48:22.227520Z","shell.execute_reply.started":"2022-12-01T16:48:22.221302Z","shell.execute_reply":"2022-12-01T16:48:22.226496Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# new_model = model\n# new_model.evaluate(X_val, y_val)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:48:22.232029Z","iopub.execute_input":"2022-12-01T16:48:22.232514Z","iopub.status.idle":"2022-12-01T16:48:22.239149Z","shell.execute_reply.started":"2022-12-01T16:48:22.232487Z","shell.execute_reply":"2022-12-01T16:48:22.238067Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# model.fit(X_val, y_val,\n#           epochs = 2, batch_size = batch_size, verbose = 1,\n# #           validation_data = (X_val, y_val),\n#           callbacks = [reduce_lr, es,mc],class_weight=class_weight)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:48:22.240661Z","iopub.execute_input":"2022-12-01T16:48:22.241267Z","iopub.status.idle":"2022-12-01T16:48:22.251977Z","shell.execute_reply.started":"2022-12-01T16:48:22.241209Z","shell.execute_reply":"2022-12-01T16:48:22.250864Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"# model = new_model ","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:48:22.253239Z","iopub.execute_input":"2022-12-01T16:48:22.254068Z","iopub.status.idle":"2022-12-01T16:48:22.264892Z","shell.execute_reply.started":"2022-12-01T16:48:22.254032Z","shell.execute_reply":"2022-12-01T16:48:22.263667Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"### Testing\n***\nConverting the test data into sequences of integers and padding them.  \nLoading the best model and calculating the accuracy","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/int3405-sentiment-analysis-problem/test.csv')\ndata_test = pd.DataFrame({'input':df['Comment'],'id':df[\"RevId\"]})\nX_test = list(data_test['input'].values)\n\ndef clean_text_test(X):\n    idx = 0\n    y_train = []\n    processed = []\n    for text in X:\n        text = str(text)\n        text = clean_text_2(text)\n        input_text_pre_accent = ViTokenizer.tokenize(text)\n        processed.append(input_text_pre_accent)\n    return processed\n# X_test = list()\nX_test_final = clean_text_test(X_test)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:48:22.267409Z","iopub.execute_input":"2022-12-01T16:48:22.268135Z","iopub.status.idle":"2022-12-01T16:48:30.979580Z","shell.execute_reply.started":"2022-12-01T16:48:22.268099Z","shell.execute_reply":"2022-12-01T16:48:30.978607Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"tokenized_word_list = tokenizer.texts_to_sequences(X_test_final)\nX_test_padded = pad_sequences(tokenized_word_list, maxlen = maxlen, padding='post')\ny_pred = model.predict(X_test_padded)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:48:30.980967Z","iopub.execute_input":"2022-12-01T16:48:30.981419Z","iopub.status.idle":"2022-12-01T16:48:37.010762Z","shell.execute_reply.started":"2022-12-01T16:48:30.981377Z","shell.execute_reply":"2022-12-01T16:48:37.009769Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stderr","text":"2022-12-01 16:48:31.461297: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\nop: \"FlatMapDataset\"\ninput: \"PrefetchDataset/_8\"\nattr {\n  key: \"Targuments\"\n  value {\n    list {\n    }\n  }\n}\nattr {\n  key: \"f\"\n  value {\n    func {\n      name: \"__inference_Dataset_flat_map_slice_batch_indices_16687\"\n    }\n  }\n}\nattr {\n  key: \"output_shapes\"\n  value {\n    list {\n      shape {\n        dim {\n          size: -1\n        }\n      }\n    }\n  }\n}\nattr {\n  key: \"output_types\"\n  value {\n    list {\n      type: DT_INT64\n    }\n  }\n}\n. Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","output_type":"stream"}]},{"cell_type":"code","source":"# X_test_final[:10]","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:48:37.015409Z","iopub.execute_input":"2022-12-01T16:48:37.015694Z","iopub.status.idle":"2022-12-01T16:48:37.019791Z","shell.execute_reply.started":"2022-12-01T16:48:37.015668Z","shell.execute_reply":"2022-12-01T16:48:37.018868Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"print(y_pred[:20])\nprint(np.shape(y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:48:37.021405Z","iopub.execute_input":"2022-12-01T16:48:37.022459Z","iopub.status.idle":"2022-12-01T16:48:37.034294Z","shell.execute_reply.started":"2022-12-01T16:48:37.022355Z","shell.execute_reply":"2022-12-01T16:48:37.032893Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"[[0.19462317]\n [0.56596226]\n [0.920395  ]\n [0.30329537]\n [0.88999236]\n [0.94905597]\n [0.9415392 ]\n [0.8654884 ]\n [0.06212769]\n [0.05125832]\n [0.91135913]\n [0.7469138 ]\n [0.02955581]\n [0.952119  ]\n [0.92897075]\n [0.733113  ]\n [0.9707427 ]\n [0.9524193 ]\n [0.9514696 ]\n [0.861404  ]]\n(5103, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(X_test_final[9])","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:48:37.035758Z","iopub.execute_input":"2022-12-01T16:48:37.036879Z","iopub.status.idle":"2022-12-01T16:48:37.045574Z","shell.execute_reply.started":"2022-12-01T16:48:37.036843Z","shell.execute_reply":"2022-12-01T16:48:37.044256Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"qu√° tr∆∞a ƒë·ªãnh ƒëi th·ª≠ ph·ªü th√¨n ·ªü l√≤_ƒë√∫c c∆° , nh∆∞ng m√† ƒë∆∞·ªùng xa m·ªèi g·ªëi , th·∫ø qu√°i n√†o l·∫°i s√† v√†o c√°i qu√°n n√†y . g√† t·∫ßn 55k ( kh√¥ng nh·ªõ 55k hay 65k g√¨ ƒë·∫•y ) , th√™m m√¨ g√≥i tr·∫ßn n∆∞·ªõc s√¥i + 10k . ƒë∆∞·ª£c c√°i l√† g√†_√°c , nh∆∞ng t·∫ßn r·∫•t √≠t v·ªã thu·ªëc , ng·∫£i_c·ª©u c≈©ng ch·ªâ ƒë∆∞·ª£c 1 t·∫πo , n∆∞·ªõc c≈©ng ch·ªâ ƒë∆∞·ª£c 1 t√≠ . c√≥_l·∫Ω v√¨ con g√† ƒë√£ chi·∫øm h·∫øt di·ªán_t√≠ch ·ªëng_b∆° . g√† ƒë√£ t·∫ßn s·∫µn ƒë·ªÉ trong ·ªëng_b∆° , kh√°ch g·ªçi m·ªõi tr·∫ßn l·∫°i cho √¢m_·∫•m . xong ƒë·ªï ra b√°t 1 ƒë·ªëng tr√¥ng r·∫•t m·∫•t c·∫£m_t√¨nh . c√°_nh√¢n m√¨nh th·∫•y v·ªã d·ªü v√¥_c√πng d·ªü .\n","output_type":"stream"}]},{"cell_type":"code","source":"print(X_test_final[12])\nprint(y_pred[12])","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:48:37.047531Z","iopub.execute_input":"2022-12-01T16:48:37.048424Z","iopub.status.idle":"2022-12-01T16:48:37.057906Z","shell.execute_reply.started":"2022-12-01T16:48:37.048385Z","shell.execute_reply":"2022-12-01T16:48:37.056864Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"t√¥i v·ª´a ƒë·∫∑t 1 xu·∫•t c∆°m v·ªãt m·∫•t 70 tr√™n now nh∆∞ng c·ª≠a_h√†ng l·∫°i qu√™n ko cho v·ªãt v√†o\n[0.02955581]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(X_test_final[1])\nprint(y_pred[1])","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:48:37.059292Z","iopub.execute_input":"2022-12-01T16:48:37.059795Z","iopub.status.idle":"2022-12-01T16:48:37.073052Z","shell.execute_reply.started":"2022-12-01T16:48:37.059758Z","shell.execute_reply":"2022-12-01T16:48:37.071856Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"h√¥m r·ªìi trung_t√¢m m√¨nh t·ªï_ch·ª©c noel party ·ªü ƒë√¢y v√¨ mua ƒë∆∞·ª£c voucher 150k / ng∆∞·ªùi su·∫•t buffet l·∫©u ·∫° . nh√†_h√†ng n·∫±m tr√™n ƒë·∫ßu ƒë∆∞·ªùng th√°i th·ªãnh r·∫•t to , nh√¨n c√≥ v·∫ª chuy√™n v·ªÅ h·ªôi_ngh·ªã ti·ªác c∆∞·ªõi h∆°n . b·ªüi_v·∫≠y n√™n buffet ·ªü ƒë√¢y l√† k√™u nh√¢n_vi√™n ƒëem ra ch·ª© kh√¥ng t·ª± l·∫•y ·∫° . n∆∞·ªõc l·∫©u kh√° nh·∫°t , kh√¥ng c√≥ g√¨ ƒë·∫∑c_s·∫Øc , m√¨nh ph·∫£i xin th√™m sa t·∫ø b·ªè v√†o m·ªõi c√≥ t√≠ v·ªã . ƒë·ªì nh√∫ng l·∫©u g·ªìm c√≥ th·ªãt b√≤ , c√° vi√™n , t√¥m , ch·∫£ c√° ... mang_ti·∫øng buffet nh∆∞ng t√¥m kh√¥ng ƒë∆∞·ª£c g·ªçi th√™m ƒë√¢u ·∫° : ) ) ) ch·ªâ ƒë∆∞·ª£c ƒë√∫ng v√†i con mang ra ƒëƒ©a ƒë·∫ßu_ti√™n th√¥i . g·∫ßu b√≤ ƒÉn kh√¥ v√† ch√°n l·∫Øm n√™n m√¨nh ch·ªâ g·ªçi ba_ch·ªâ b√≤ , nh∆∞ng khi g·ªçi th√™m nh·ªØng l·∫ßn sau th√¨ nh√¢n_vi√™n ƒëem ra c·ª±c_k√¨ l√¢u , n√≥i_chung l√† kh√¥ng nhi·ªát_t√¨nh , c√≤n nhƒÉn_nh√≥ kh√≥_ch·ªãu n·ªØa . h√¥m ƒë√≥ m·∫•y ch·ªã_em m√¨nh ƒÉn ƒë√£ kh√¥ng ngon r·ªìi c√≤n kh√¥ng no : ) ) nh∆∞ng v√¨ cty t·ªï_ch·ª©c n√™n ƒëi ƒÉn th√¥i ch·ª© kh√¥ng c√≥ s·ª± l·ª±a_ch·ªçn\n[0.56596226]\n","output_type":"stream"}]},{"cell_type":"code","source":"my_submission = pd.DataFrame({'RevId': np.array(df[\"RevId\"]).reshape(5103), 'Rating': np.array(y_pred).reshape(5103)})\nmy_submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:48:37.074324Z","iopub.execute_input":"2022-12-01T16:48:37.075690Z","iopub.status.idle":"2022-12-01T16:48:37.100204Z","shell.execute_reply.started":"2022-12-01T16:48:37.075651Z","shell.execute_reply":"2022-12-01T16:48:37.099367Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"# from keras.models import load_model\nmodelload = load_model('model_best.h5', custom_objects = {\"AttentionWithContext\" : AttentionWithContext, \"backend\" : backend})\ny_pred = model.predict(X_test_padded)\nprint(y_pred[:20])\nprint(np.shape(y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:48:37.102614Z","iopub.execute_input":"2022-12-01T16:48:37.103464Z","iopub.status.idle":"2022-12-01T16:48:40.983711Z","shell.execute_reply.started":"2022-12-01T16:48:37.103420Z","shell.execute_reply":"2022-12-01T16:48:40.982527Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stderr","text":"2022-12-01 16:48:37.747982: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\nop: \"FlatMapDataset\"\ninput: \"PrefetchDataset/_8\"\nattr {\n  key: \"Targuments\"\n  value {\n    list {\n    }\n  }\n}\nattr {\n  key: \"f\"\n  value {\n    func {\n      name: \"__inference_Dataset_flat_map_slice_batch_indices_20486\"\n    }\n  }\n}\nattr {\n  key: \"output_shapes\"\n  value {\n    list {\n      shape {\n        dim {\n          size: -1\n        }\n      }\n    }\n  }\n}\nattr {\n  key: \"output_types\"\n  value {\n    list {\n      type: DT_INT64\n    }\n  }\n}\n. Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","output_type":"stream"},{"name":"stdout","text":"[[0.19462317]\n [0.56596226]\n [0.920395  ]\n [0.30329537]\n [0.88999236]\n [0.94905597]\n [0.9415392 ]\n [0.8654884 ]\n [0.06212769]\n [0.05125832]\n [0.91135913]\n [0.7469138 ]\n [0.02955581]\n [0.952119  ]\n [0.92897075]\n [0.733113  ]\n [0.9707427 ]\n [0.9524193 ]\n [0.9514696 ]\n [0.861404  ]]\n(5103, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"my_submission['Rating'].sum()/len(my_submission['Rating'])","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:48:40.988669Z","iopub.execute_input":"2022-12-01T16:48:40.991680Z","iopub.status.idle":"2022-12-01T16:48:41.005870Z","shell.execute_reply.started":"2022-12-01T16:48:40.991637Z","shell.execute_reply":"2022-12-01T16:48:41.004556Z"},"trusted":true},"execution_count":70,"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"0.6680664923666225"},"metadata":{}}]},{"cell_type":"code","source":"my_submission = pd.DataFrame({'RevId': np.array(df[\"RevId\"]).reshape(5103), 'Rating': np.array(y_pred).reshape(5103)})\nmy_submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:48:41.011119Z","iopub.execute_input":"2022-12-01T16:48:41.012136Z","iopub.status.idle":"2022-12-01T16:48:41.034370Z","shell.execute_reply.started":"2022-12-01T16:48:41.012095Z","shell.execute_reply":"2022-12-01T16:48:41.033387Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}